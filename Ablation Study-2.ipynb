{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nasbench import api\n",
    "from search_spaces import load_nasbench_101\n",
    "from random_search import run_random_search, random_spec\n",
    "from neural_predictor import classifier, regressor, regressor_mlp, regressor_cnn\n",
    "from input_preprocessing import preprocess_nasbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file... This may take a few minutes...\n",
      "WARNING:tensorflow:From /data2/home/patara/CS470-Project-Team3/nasbench/api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Loaded dataset in 44 seconds\n"
     ]
    }
   ],
   "source": [
    "nasbench = load_nasbench_101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_samples(N):\n",
    "    models = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        while True:\n",
    "            model = random_spec(nasbench)\n",
    "            if model not in models:\n",
    "                models.append(nasbench.query(model))\n",
    "                break\n",
    "                \n",
    "    return preprocess_nasbench(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation Study 1: N vs K and Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOPS = 60\n",
    "MAX_SAMPLES = 5000\n",
    "MAX_TIME_BUDGET = 8e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for N in [43, 86, 129, 172, 344, 860]:\n",
    "    train_data = get_N_samples(N)\n",
    "    reg = regressor([train_data['X'], train_data['norm_A'], train_data['norm_AT']], train_data['val_acc'])\n",
    "    train_time = np.sum(train_data['times'])\n",
    "    \n",
    "    np_val_avg, np_test_avg = [], []\n",
    "    np_val_std, np_test_std = [], []\n",
    "\n",
    "    val_acc, test_acc = [], []\n",
    "    for budget in tqdm(range(int(train_time), int(MAX_TIME_BUDGET), 1600)): # 500 loops\n",
    "        time_spent = 0\n",
    "        test_models = get_N_samples(N+budget//100)\n",
    "\n",
    "        for i in range(len(test_models['times'])):\n",
    "            time_spent = time_spent + test_models['times'][i]\n",
    "            if time_spent >= budget:\n",
    "                break\n",
    "\n",
    "        X = test_models['X'][:i]\n",
    "        A = test_models['norm_A'][:i]\n",
    "        AT = test_models['norm_AT'][:i]\n",
    "        labels = test_models['val_acc'][:i]\n",
    "        test_labels = test_models['test_acc'][:i]\n",
    "\n",
    "        pred_acc = reg.predict([X, A, AT]).ravel()\n",
    "\n",
    "        selected_val = labels\n",
    "        selected_test = test_labels\n",
    "\n",
    "        best_val_idx = np.argmax(selected_val)\n",
    "\n",
    "        val_acc.append(selected_val[best_val_idx])\n",
    "        test_acc.append(selected_test[best_val_idx])\n",
    "\n",
    "        np_val_avg.append(np.max(val_acc))\n",
    "        np_val_std.append(np.std(val_acc))\n",
    "\n",
    "        np_test_avg.append(np.max(test_acc))\n",
    "        np_test_std.append(np.std(test_acc))\n",
    "\n",
    "    results[N] = {\n",
    "        'np_val_avg': np_val_avg,\n",
    "        'np_test_avg': np_test_avg,\n",
    "        'np_val_std': np_val_std,\n",
    "        'np_test_std': np_test_std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/ablation_study_by_time.npy', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation Study 2: MLP vs CNN vs GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8562069d1b040b48b12fcd87aba8650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLP\n",
    "N = 172\n",
    "train_data = get_N_samples(N)\n",
    "reg = regressor_mlp(np.concatenate([train_data['X'], train_data['norm_A']], axis=-1), train_data['val_acc'])\n",
    "train_time = np.sum(train_data['times'])\n",
    "\n",
    "np_val_avg, np_test_avg = [], []\n",
    "np_val_std, np_test_std = [], []\n",
    "\n",
    "val_acc, test_acc = [], []\n",
    "for budget in tqdm(range(int(train_time), int(MAX_TIME_BUDGET), 1600)): # 500 loops\n",
    "    time_spent = 0\n",
    "    test_models = get_N_samples(N+budget//100)\n",
    "\n",
    "    for i in range(len(test_models['times'])):\n",
    "        time_spent = time_spent + test_models['times'][i]\n",
    "        if time_spent >= budget:\n",
    "            break\n",
    "\n",
    "    X = test_models['X'][:i]\n",
    "    A = test_models['norm_A'][:i]\n",
    "    AT = test_models['norm_AT'][:i]\n",
    "    labels = test_models['val_acc'][:i]\n",
    "    test_labels = test_models['test_acc'][:i]\n",
    "\n",
    "    pred_acc = reg.predict(np.concatenate([X, A], axis=-1)).ravel()\n",
    "\n",
    "    selected_val = labels\n",
    "    selected_test = test_labels\n",
    "\n",
    "    best_val_idx = np.argmax(selected_val)\n",
    "\n",
    "    val_acc.append(selected_val[best_val_idx])\n",
    "    test_acc.append(selected_test[best_val_idx])\n",
    "\n",
    "    np_val_avg.append(np.max(val_acc))\n",
    "    np_val_std.append(np.std(val_acc))\n",
    "\n",
    "    np_test_avg.append(np.max(test_acc))\n",
    "    np_test_std.append(np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mlp = {\n",
    "    'np_val_avg': np_val_avg,\n",
    "    'np_test_avg': np_test_avg,\n",
    "    'np_val_std': np_val_std,\n",
    "    'np_test_std': np_test_std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/ablation_study_by_arch_time_mlp.npy', result_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f2a10d790c432f843dfc776a6c3693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN\n",
    "N = 172\n",
    "train_data = get_N_samples(N)\n",
    "reg = regressor_cnn(np.concatenate([train_data['X'], train_data['norm_A']], axis=-1), train_data['val_acc'])\n",
    "train_time = np.sum(train_data['times'])\n",
    "\n",
    "np_val_avg, np_test_avg = [], []\n",
    "np_val_std, np_test_std = [], []\n",
    "\n",
    "val_acc, test_acc = [], []\n",
    "for budget in tqdm(range(int(train_time), int(MAX_TIME_BUDGET), 1600)): # 500 loops\n",
    "    time_spent = 0\n",
    "    test_models = get_N_samples(N+budget//100)\n",
    "\n",
    "    for i in range(len(test_models['times'])):\n",
    "        time_spent = time_spent + test_models['times'][i]\n",
    "        if time_spent >= budget:\n",
    "            break\n",
    "\n",
    "    X = test_models['X'][:i]\n",
    "    A = test_models['norm_A'][:i]\n",
    "    AT = test_models['norm_AT'][:i]\n",
    "    labels = test_models['val_acc'][:i]\n",
    "    test_labels = test_models['test_acc'][:i]\n",
    "\n",
    "    pred_acc = reg.predict(np.concatenate([X, A], axis=-1)).ravel()\n",
    "\n",
    "    selected_val = labels\n",
    "    selected_test = test_labels\n",
    "\n",
    "    best_val_idx = np.argmax(selected_val)\n",
    "\n",
    "    val_acc.append(selected_val[best_val_idx])\n",
    "    test_acc.append(selected_test[best_val_idx])\n",
    "\n",
    "    np_val_avg.append(np.max(val_acc))\n",
    "    np_val_std.append(np.std(val_acc))\n",
    "\n",
    "    np_test_avg.append(np.max(test_acc))\n",
    "    np_test_std.append(np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cnn = {\n",
    "    'np_val_avg': np_val_avg,\n",
    "    'np_test_avg': np_test_avg,\n",
    "    'np_val_std': np_val_std,\n",
    "    'np_test_std': np_test_std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/ablation_study_by_arch_time_cnn.npy', result_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd88015738544518574dc9c7da6b2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GCN\n",
    "N = 172\n",
    "train_data = get_N_samples(N)\n",
    "reg = regressor([train_data['X'], train_data['norm_A'], train_data['norm_AT']], train_data['val_acc'])\n",
    "train_time = np.sum(train_data['times'])\n",
    "\n",
    "np_val_avg, np_test_avg = [], []\n",
    "np_val_std, np_test_std = [], []\n",
    "\n",
    "val_acc, test_acc = [], []\n",
    "for budget in tqdm(range(int(train_time), int(MAX_TIME_BUDGET), 1600)): # 500 loops\n",
    "    time_spent = 0\n",
    "    test_models = get_N_samples(N+budget//100)\n",
    "\n",
    "    for i in range(len(test_models['times'])):\n",
    "        time_spent = time_spent + test_models['times'][i]\n",
    "        if time_spent >= budget:\n",
    "            break\n",
    "\n",
    "    X = test_models['X'][:i]\n",
    "    A = test_models['norm_A'][:i]\n",
    "    AT = test_models['norm_AT'][:i]\n",
    "    labels = test_models['val_acc'][:i]\n",
    "    test_labels = test_models['test_acc'][:i]\n",
    "\n",
    "    pred_acc = reg.predict([X, A, AT]).ravel()\n",
    "\n",
    "    selected_val = labels\n",
    "    selected_test = test_labels\n",
    "\n",
    "    best_val_idx = np.argmax(selected_val)\n",
    "\n",
    "    val_acc.append(selected_val[best_val_idx])\n",
    "    test_acc.append(selected_test[best_val_idx])\n",
    "\n",
    "    np_val_avg.append(np.max(val_acc))\n",
    "    np_val_std.append(np.std(val_acc))\n",
    "\n",
    "    np_test_avg.append(np.max(test_acc))\n",
    "    np_test_std.append(np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gcn = {\n",
    "    'np_val_avg': np_val_avg,\n",
    "    'np_test_avg': np_test_avg,\n",
    "    'np_val_std': np_val_std,\n",
    "    'np_test_std': np_test_std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/ablation_study_by_arch_time_gcn.npy', result_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
