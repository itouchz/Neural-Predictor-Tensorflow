{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dear Team 2,\n",
    "\n",
    "We provide Project 2 Progress Feeback as below:\n",
    "\n",
    "It would be good to experiment with other benchmark datasets or sampling techniques for further improvement, but it would sufficiently explain why your team has applied other sampling techniques.  <br>\n",
    "Additionally, as shown in the baseline paper, it would be better to show the plot.\n",
    "It seems that there are quite a lot of experiments to be carried out. So I think it will be a good project if you distribute the remaining period appropriately and proceed with the experiment. <br>\n",
    "It's hard to understand because the presentation is fast.\n",
    "The project seems to be going well. However, it would be better to have a more specific explanation on how to improve.\n",
    "\n",
    "Sincerely,\n",
    "Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CosineDecay' from 'tensorflow.keras.optimizers.schedules' (/home/patara/anaconda3/envs/patara/lib/python3.7/site-packages/tensorflow/keras/optimizers/schedules/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a7706c924fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnasbench_nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnas_environment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_predictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Courses/CS470-Project-Team3/neural_predictor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineDecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspektral\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAvgPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CosineDecay' from 'tensorflow.keras.optimizers.schedules' (/home/patara/anaconda3/envs/patara/lib/python3.7/site-packages/tensorflow/keras/optimizers/schedules/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nasbench_nlp.nas_environment import Environment\n",
    "from neural_predictor import regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = ['cifar100', 'caltech101', 'oxford_iiit_pet', 'oxford_flowers102']\n",
    "text_datasets = ['imdb_reviews', 'yelp_polarity_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on New Benchmark Datasets (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_logs_path = 'nasbench_nlp/train_logs_single_run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(precomputed_logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_set = env.get_precomputed_recepies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, test_loss = [], []\n",
    "    \n",
    "env.reset()\n",
    "for s in search_set:\n",
    "    env.simulated_train(s, 50)\n",
    "    if 'OK' == env.get_model_status(s):\n",
    "        stats = env.get_model_stats(s, 49)\n",
    "        val_loss.append(stats['val_loss'])\n",
    "        test_loss.append(stats['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41530952065678 0.5854086570687619\n",
      "4.368057399120145 0.5847845925439688\n"
     ]
    }
   ],
   "source": [
    "print(np.min(val_loss), np.std(val_loss))\n",
    "print(np.min(test_loss), np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = {'val_loss': val_loss, 'test_loss': test_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, test_loss = [], []\n",
    "\n",
    "env.reset()\n",
    "val_loss_i, test_loss_i = [], []\n",
    "for _ in range(2000):\n",
    "    idx = np.random.choice(len(search_set), 1, replace=False)[0]\n",
    "    s = search_set[idx]\n",
    "    \n",
    "    env.simulated_train(s, 50)\n",
    "    \n",
    "    if 'OK' == env.get_model_status(s):\n",
    "        stats = env.get_model_stats(s, 49)\n",
    "        val_loss_i.append(stats['val_loss'])\n",
    "        test_loss_i.append(stats['test_loss'])\n",
    "        \n",
    "    val_loss.append(np.min(val_loss_i))\n",
    "    test_loss.append(np.min(test_loss_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = {'val_loss': val_loss, 'test_loss': test_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, test_loss = [], []\n",
    "\n",
    "env.reset()\n",
    "val_loss_i, test_loss_i = [], []\n",
    "for K in range(2000-172):\n",
    "    K = k + 1\n",
    "    idx = np.random.choice(len(search_set), 172+K, replace=False)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
