{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nasbench_nlp.nas_environment import Environment\n",
    "from neural_predictor import regressor\n",
    "from input_preprocessing import preprocess_nasbench_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on New Benchmark Datasets (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_logs_path = 'nasbench_nlp/train_logs_single_run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(precomputed_logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_set = env.get_precomputed_recepies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOPS = 60\n",
    "MAX_SAMPLES = 500\n",
    "MAX_TIME_BUDGET = 8e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, test_loss = [], []\n",
    "    \n",
    "env.reset()\n",
    "for s in search_set:\n",
    "    env.simulated_train(s, 50)\n",
    "    if 'OK' == env.get_model_status(s):\n",
    "        stats = env.get_model_stats(s, 49)\n",
    "        val_loss.append(stats['val_loss'])\n",
    "        test_loss.append(stats['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41530952065678 0.5854086570687619\n",
      "4.368057399120145 0.5847845925439688\n"
     ]
    }
   ],
   "source": [
    "print(np.min(val_loss), np.std(val_loss))\n",
    "print(np.min(test_loss), np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = {'val_loss': val_loss, 'test_loss': test_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679bf08857d143eca476211c685ad961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "random_val_avg, random_test_avg = [], []\n",
    "random_val_std, random_test_std = [], []\n",
    "\n",
    "val_loss, test_loss = [], []\n",
    "for _ in tqdm(range(MAX_SAMPLES)):\n",
    "    loop_val, loop_test = [], []\n",
    "    for _ in range(LOOPS):\n",
    "        idx = np.random.choice(len(search_set), 1, replace=False)[0]\n",
    "        s = search_set[idx]\n",
    "\n",
    "        env.simulated_train(s, 50)\n",
    "        if 'OK' == env.get_model_status(s):\n",
    "            stats = env.get_model_stats(s, 49)\n",
    "            loop_val.append(stats['val_loss'])\n",
    "            loop_test.append(stats['test_loss'])\n",
    "\n",
    "    val_loss.append(np.mean(loop_val))\n",
    "    test_loss.append(np.mean(loop_test))\n",
    "    \n",
    "    random_val_avg.append(np.min(val_loss))\n",
    "    random_val_std.append(np.std(loop_val))\n",
    "    \n",
    "    random_test_avg.append(np.min(test_loss))\n",
    "    random_test_std.append(np.std(loop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/nlp_random_val_avg_by_samples.npy', random_val_avg)\n",
    "np.save('outputs/nlp_random_val_std_by_samples.npy', random_val_std)\n",
    "np.save('outputs/nlp_random_test_avg_by_samples.npy', random_test_avg)\n",
    "np.save('outputs/nlp_random_test_std_by_samples.npy', random_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da982387cc04833b323a841e6b51212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_val_avg, random_test_avg = [], []\n",
    "random_val_std, random_test_std = [], []\n",
    "\n",
    "val_loss, test_loss = [], []\n",
    "for budget in tqdm(range(0, int(MAX_TIME_BUDGET), 1600)): # 500 loops\n",
    "    loop_val, loop_test = [], []\n",
    "\n",
    "    for _ in range(LOOPS):\n",
    "        while True:\n",
    "            time_spent = 0\n",
    "            idx = np.random.choice(len(search_set), 1, replace=False)[0]\n",
    "            s = search_set[idx]\n",
    "\n",
    "            env.simulated_train(s, 50)\n",
    "            if 'OK' == env.get_model_status(s):\n",
    "                stats = env.get_model_stats(s, 49)\n",
    "                loop_val.append(stats['val_loss'])\n",
    "                loop_test.append(stats['test_loss'])\n",
    "                time_spent += stats['wall_time']\n",
    "                if time_spent > budget:\n",
    "                    break\n",
    "    \n",
    "    val_loss.append(np.mean(loop_val))\n",
    "    test_loss.append(np.mean(loop_test))\n",
    "    \n",
    "    random_val_avg.append(np.min(val_loss))\n",
    "    random_val_std.append(np.std(loop_val))\n",
    "    \n",
    "    random_test_avg.append(np.min(test_loss))\n",
    "    random_test_std.append(np.std(loop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/nlp_random_val_avg_by_time.npy', random_val_avg)\n",
    "np.save('outputs/nlp_random_val_std_by_time.npy', random_val_std)\n",
    "np.save('outputs/nlp_random_test_avg_by_time.npy', random_test_avg)\n",
    "np.save('outputs/nlp_random_test_std_by_time.npy', random_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nodes <= 24, number of hidden states <= 3, number of linear input vectors n <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss, test_loss = [], []\n",
    "\n",
    "# env.reset()\n",
    "# val_loss_i, test_loss_i = [], []\n",
    "# for K in range(2000-172):\n",
    "#     K = k + 1\n",
    "#     idx = np.random.choice(len(search_set), 172+K, replace=False)[0]\n",
    "\n",
    "#     s = search_set[idx]\n",
    "#     env.simulated_train(s, 50)\n",
    "    \n",
    "#     if 'OK' == env.get_model_status(s):\n",
    "#         stats = env.get_model_stats(s, 49)\n",
    "#         val_loss_i.append(stats['val_loss'])\n",
    "#         test_loss_i.append(stats['test_loss'])\n",
    "        \n",
    "#     val_loss.append(np.min(val_loss_i))\n",
    "#     test_loss.append(np.min(test_loss_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 172\n",
    "def get_N_samples(N):\n",
    "    env.reset()\n",
    "    \n",
    "    models = []\n",
    "    stats = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        while True:\n",
    "            idx = np.random.choice(len(search_set), 1, replace=False)[0]\n",
    "            model = search_set[idx]\n",
    "            \n",
    "            if model not in models:\n",
    "                env.simulated_train(model, 50)\n",
    "                \n",
    "                if 'OK' == env.get_model_status(model):   \n",
    "                    models.append(model)\n",
    "                    stats.append(env.get_model_stats(model, 49))\n",
    "                    break\n",
    "                \n",
    "    return preprocess_nasbench_nlp(models, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training part\n",
    "train_data = get_N_samples(N)\n",
    "reg = regressor([train_data['X'], train_data['norm_A'], train_data['norm_AT']], train_data['val_loss'], mode='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b396563b814a1db150cd5e0989915d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing part\n",
    "np_val_avg, np_test_avg = [], []\n",
    "np_val_std, np_test_std = [], []\n",
    "\n",
    "val_acc, test_acc = [], []\n",
    "for k in tqdm(range(MAX_SAMPLES - N)):\n",
    "    K = k + 1\n",
    "\n",
    "    loop_val, loop_test = [], []\n",
    "    for _ in range(LOOPS):\n",
    "        test_models = get_N_samples(N+K)\n",
    "        pred_acc = reg.predict([test_models['X'], test_models['norm_A'], test_models['norm_AT']]).ravel()\n",
    "        \n",
    "        topk_idx = tf.math.top_k(-pred_acc, k=K).indices.numpy()\n",
    "        selected_val = test_models['val_loss'][topk_idx]\n",
    "        selected_test = test_models['test_loss'][topk_idx]\n",
    "        \n",
    "        best_val_idx = np.argmin(selected_val)\n",
    "        \n",
    "        loop_val.append(selected_val[best_val_idx])\n",
    "        loop_test.append(selected_test[best_val_idx])\n",
    "\n",
    "    val_acc.append(np.mean(loop_val))\n",
    "    test_acc.append(np.mean(loop_test))\n",
    "    \n",
    "    np_val_avg.append(np.min(val_acc))\n",
    "    np_val_std.append(np.std(loop_val))\n",
    "    \n",
    "    np_test_avg.append(np.min(test_acc))\n",
    "    np_test_std.append(np.std(loop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/nlp_np_val_avg_by_samples.npy', np_val_avg)\n",
    "np.save('outputs/nlp_np_val_std_by_samples.npy', np_val_std)\n",
    "np.save('outputs/nlp_np_test_avg_by_samples.npy', np_test_avg)\n",
    "np.save('outputs/nlp_np_test_std_by_samples.npy', np_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_val_avg, np_test_avg = [], []\n",
    "np_val_std, np_test_std = [], []\n",
    "\n",
    "val_acc, test_acc = [], []\n",
    "for budget in tqdm(range(int(train_time), int(MAX_TIME_BUDGET), 1600)): # 5000 loops\n",
    "        \n",
    "    loop_val, loop_test = [], []\n",
    "    for _ in range(LOOPS):\n",
    "        time_spent = 0\n",
    "        test_models = get_N_samples(N+budget//100)\n",
    "        \n",
    "        for i in range(len(test_models['times'])):\n",
    "            time_spent = time_spent + test_models['times'][i]\n",
    "            if time_spent >= budget:\n",
    "                break\n",
    "        \n",
    "        X = test_models['X'][:i]\n",
    "        A = test_models['norm_A'][:i]\n",
    "        AT = test_models['norm_AT'][:i]\n",
    "        labels = test_models['val_acc'][:i]\n",
    "        test_labels = test_models['test_acc'][:i]\n",
    "        \n",
    "        pred_acc = reg.predict([X, A, AT]).ravel()\n",
    "        \n",
    "        selected_val = labels\n",
    "        selected_test = test_labels\n",
    "        \n",
    "        best_val_idx = np.argmax(selected_val)\n",
    "        \n",
    "        loop_val.append(selected_val[best_val_idx])\n",
    "        loop_test.append(selected_test[best_val_idx])\n",
    "\n",
    "    val_acc.append(np.mean(loop_val))\n",
    "    test_acc.append(np.mean(loop_test))\n",
    "    \n",
    "    np_val_avg.append(np.max(val_acc))\n",
    "    np_val_std.append(np.std(loop_val))\n",
    "    \n",
    "    np_test_avg.append(np.max(test_acc))\n",
    "    np_test_std.append(np.std(loop_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
