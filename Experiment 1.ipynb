{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "source": [
    "## NASBench-101"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Search Space Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Oracle: An Upper Bound Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
    "!git clone https://github.com/google-research/nasbench\n",
    "!pip install ./nasbench\n",
    "\n",
    "from nasbench import api\n",
    "nasbench = api.NASBench('nasbench_full.tfrecord')"
   ]
  },
  {
   "source": [
    "### Random Search: A Lower Bound Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the raw data (only 108 epoch data points, for full dataset,\n",
    "# uncomment the second line for nasbench_full.tfrecord).\n",
    "\n",
    "if not os.path.exists('nasbench_full.tfrecord'):\n",
    "  !curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
    "\n",
    "# Clone and install the code and dependencies.\n",
    "\n",
    "!git clone https://github.com/google-research/nasbench\n",
    "!pip install ./nasbench\n",
    "\n",
    "# Initialize the NASBench object which parses the raw data into memory (this\n",
    "# should only be run once as it takes up to a few minutes).\n",
    "from nasbench import api\n",
    "\n",
    "# Use nasbench_full.tfrecord for full dataset (run download command above).\n",
    "nasbench = api.NASBench('nasbench_full.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "full_metrics = nasbench.computed_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Performance Test\n",
    "best_val_acc = []\n",
    "best_test_acc = []\n",
    "\n",
    "for _, full_metric in tqdm(full_metrics.items()):\n",
    "  for _, metric in full_metric.items():\n",
    "    avg_val_acc = np.average([m['final_validation_accuracy'] for m in metric])\n",
    "    avg_test_acc = np.average([m['final_test_accuracy'] for m in metric])\n",
    "\n",
    "  best_val_acc.append(max_val_acc)\n",
    "  best_test_acc.append(max_test_acc)"
   ]
  },
  {
   "source": [
    "max_val_acc = np.amax(best_val_acc)\n",
    "corr_test_acc = best_test_acc[np.argmax(best_val_acc)]\n",
    "\n",
    "max_test_acc = np.amax(best_test_acc)\n",
    "corr_val_acc = best_val_acc[np.argmax(best_test_acc)]\n",
    "\n",
    "print(\"Best Performance\")\n",
    "print(f\"\\033[1mval: {max_val_acc}\\033[0m test: {corr_test_acc}\")\n",
    "print(f\"val: {corr_val_acc} \\033[1mtest: {max_test_acc}\\033[0m\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Test (will be used as oracle)\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# Repeat oracle method for 100 times\n",
    "for _ in tqdm(range(100)):\n",
    "  max_val_acc = 0\n",
    "  max_test_acc = 0\n",
    "\n",
    "  for _, full_metric in full_metrics.items():\n",
    "    for _, metric in full_metric.items():\n",
    "      sample_metric = random.choice(metric)\n",
    "      sample_val_acc = sample_metric['final_validation_accuracy']\n",
    "      sample_test_acc = sample_metric['final_test_accuracy']\n",
    "\n",
    "      if sample_val_acc > max_val_acc:\n",
    "        max_val_acc = sample_val_acc\n",
    "      if sample_test_acc > max_test_acc:\n",
    "        max_test_acc = sample_test_acc\n",
    "\n",
    "  val_acc.append(max_val_acc)\n",
    "  test_acc.append(max_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_acc = np.average(val_acc)\n",
    "std_val_acc = np.std(val_acc)\n",
    "\n",
    "avg_test_acc = np.average(test_acc)\n",
    "std_test_acc = np.std(test_acc)\n",
    "\n",
    "print(\"\\nBest Validation Accuracy\")\n",
    "print(f\"avg: {avg_val_acc} std: {std_val_acc}\")\n",
    "\n",
    "print(\"\\nBest Test Accuracy\")\n",
    "print(f\"avg: {avg_test_acc} std: {std_test_acc}\")"
   ]
  },
  {
   "source": [
    "### Neural Predictor (Two Stages)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Neural Predictor (Single Stage)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### N vs K and Ablation Study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}